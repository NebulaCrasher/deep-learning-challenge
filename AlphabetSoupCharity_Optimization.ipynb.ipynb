{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "application_df.drop([\"EIN\",\"NAME\"], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLICATION_TYPE:        17\n",
      "AFFILIATION     :         6\n",
      "CLASSIFICATION  :        71\n",
      "USE_CASE        :         5\n",
      "ORGANIZATION    :         4\n",
      "STATUS          :         2\n",
      "INCOME_AMT      :         9\n",
      "SPECIAL_CONSIDERATIONS:   2\n",
      "ASK_AMT         :      8747\n",
      "IS_SUCCESSFUL   :         2\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of unique values in each column. Also satisfying OCD with string formatting\n",
    "for column in application_df:\n",
    "    series = len(application_df[column].unique())\n",
    "    if column == \"SPECIAL_CONSIDERATIONS\":\n",
    "        print(f\"{column:<10}:{series:>4}\")\n",
    "    else:\n",
    "        print(f\"{column:<16}:{series:>10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "application_df[\"APPLICATION_TYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 1 at Optimization, increasing bins available\n",
    "application_types_to_replace = [\"T25\", \"T14\", \"T29\", \"T15\", \"T17\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "T9         156\n",
       "T13         66\n",
       "T12         27\n",
       "T2          16\n",
       "Other       11\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C1800       15\n",
       "C6000       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1238       10\n",
       "C1278       10\n",
       "C1235        9\n",
       "C1237        9\n",
       "C7210        7\n",
       "C2400        6\n",
       "C1720        6\n",
       "C4100        6\n",
       "C1257        5\n",
       "C1600        5\n",
       "C1260        3\n",
       "C2710        3\n",
       "C0           3\n",
       "C3200        2\n",
       "C1234        2\n",
       "C1246        2\n",
       "C1267        2\n",
       "C1256        2\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "classification_bins = application_df[\"CLASSIFICATION\"].value_counts()\n",
    "classification_bins.loc[classification_bins > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt at Optimization, increasing bins available\n",
    "classification_index =  classification_bins.index\n",
    "keep_values = [\"C1000\", \"C2000\",\"C1200\", \"C3000\", \"C2100\", \"C7000\", \"C1700\", \"C4000\", \"C5000\", \"C1270\", \"C2700\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "Other      669\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications_to_replace = []\n",
    "\n",
    "for item in classification_index:\n",
    "    if item not in keep_values:\n",
    "        classifications_to_replace.append(item)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T12</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T2</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>...</th>\n",
       "      <th>ASK_AMT_1665460552</th>\n",
       "      <th>ASK_AMT_1736232349</th>\n",
       "      <th>ASK_AMT_1893400128</th>\n",
       "      <th>ASK_AMT_2264109450</th>\n",
       "      <th>ASK_AMT_2310256039</th>\n",
       "      <th>ASK_AMT_3391919220</th>\n",
       "      <th>ASK_AMT_4653011914</th>\n",
       "      <th>ASK_AMT_5591584994</th>\n",
       "      <th>ASK_AMT_8556638692</th>\n",
       "      <th>ASK_AMT_8597806340</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  IS_SUCCESSFUL  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n",
       "0       1              1                       0                     1   \n",
       "1       1              1                       0                     0   \n",
       "2       1              0                       0                     0   \n",
       "3       1              1                       0                     0   \n",
       "4       1              1                       0                     0   \n",
       "\n",
       "   APPLICATION_TYPE_T12  APPLICATION_TYPE_T13  APPLICATION_TYPE_T19  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   APPLICATION_TYPE_T2  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  ...  \\\n",
       "0                    0                    0                    0  ...   \n",
       "1                    0                    1                    0  ...   \n",
       "2                    0                    0                    0  ...   \n",
       "3                    0                    1                    0  ...   \n",
       "4                    0                    1                    0  ...   \n",
       "\n",
       "   ASK_AMT_1665460552  ASK_AMT_1736232349  ASK_AMT_1893400128  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   ASK_AMT_2264109450  ASK_AMT_2310256039  ASK_AMT_3391919220  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   ASK_AMT_4653011914  ASK_AMT_5591584994  ASK_AMT_8556638692  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   ASK_AMT_8597806340  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "\n",
       "[5 rows x 8800 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "dummy_variable_df = pd.get_dummies(data = application_df, columns = [\"APPLICATION_TYPE\", \"AFFILIATION\", \"CLASSIFICATION\", \"USE_CASE\", \"ORGANIZATION\", \"INCOME_AMT\", \"SPECIAL_CONSIDERATIONS\", \"ASK_AMT\"])\n",
    "dummy_variable_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = dummy_variable_df.drop(\"IS_SUCCESSFUL\", axis = 1)\n",
    "y = dummy_variable_df[\"IS_SUCCESSFUL\"]\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempting to Optimize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 500)               4400000   \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 450)               225450    \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 450)               202950    \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 400)               180400    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 401       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,259,701\n",
      "Trainable params: 5,259,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Attempt 1, adding more layers\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 500\n",
    "hidden_nodes_layer2 = 500\n",
    "hidden_nodes_layer3 = 450\n",
    "hidden_nodes_layer4 = 450\n",
    "hidden_nodes_layer5 = 400\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(input_dim = number_input_features, units=hidden_nodes_layer1, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"relu\"))\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "804/804 [==============================] - 48s 59ms/step - loss: 0.3879 - accuracy: 0.8157\n",
      "Epoch 2/5\n",
      "804/804 [==============================] - 45s 56ms/step - loss: 0.4047 - accuracy: 0.8145\n",
      "Epoch 3/5\n",
      "804/804 [==============================] - 47s 58ms/step - loss: 0.3900 - accuracy: 0.8150\n",
      "Epoch 4/5\n",
      "804/804 [==============================] - 45599s 57s/step - loss: 0.3957 - accuracy: 0.8145\n",
      "Epoch 5/5\n",
      "804/804 [==============================] - 45s 57ms/step - loss: 0.3895 - accuracy: 0.8157\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.6252 - accuracy: 0.7138 - 1s/epoch - 5ms/step\n",
      "Loss: 0.6251592040061951, Accuracy: 0.7138192653656006\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2, removing more hyper parameters\n",
    "X = dummy_variable_df.drop([\"IS_SUCCESSFUL\", \"SPECIAL_CONSIDERATIONS_N\", \"SPECIAL_CONSIDERATIONS_Y\", \"STATUS\"], axis = 1)\n",
    "y = dummy_variable_df[\"IS_SUCCESSFUL\"]\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 3125)              27490625  \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 625)               1953750   \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 125)               78250     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 126       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,522,751\n",
      "Trainable params: 29,522,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Attempt 2, creating less layers with denser connections\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 3125\n",
    "hidden_nodes_layer2 = 625\n",
    "hidden_nodes_layer3 = 125\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(input_dim = number_input_features, units=hidden_nodes_layer1, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "804/804 [==============================] - 246s 303ms/step - loss: 0.6094 - accuracy: 0.6947\n",
      "Epoch 2/5\n",
      "804/804 [==============================] - 246s 305ms/step - loss: 0.4240 - accuracy: 0.8038\n",
      "Epoch 3/5\n",
      "804/804 [==============================] - 239s 298ms/step - loss: 0.4039 - accuracy: 0.8120\n",
      "Epoch 4/5\n",
      "804/804 [==============================] - 242s 301ms/step - loss: 0.3977 - accuracy: 0.8122\n",
      "Epoch 5/5\n",
      "804/804 [==============================] - 243s 303ms/step - loss: 0.3986 - accuracy: 0.8126\n"
     ]
    }
   ],
   "source": [
    "# Attempt 2 Model Test\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 5s - loss: 0.6141 - accuracy: 0.7187 - 5s/epoch - 20ms/step\n",
      "Loss: 0.6141059398651123, Accuracy: 0.7187172174453735\n"
     ]
    }
   ],
   "source": [
    "# Attempt 2 Evaluation\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 3 Keeping all parameters the same but using different activation functions\n",
    "X = dummy_variable_df.drop([\"IS_SUCCESSFUL\"], axis = 1)\n",
    "y = dummy_variable_df[\"IS_SUCCESSFUL\"]\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 25) \n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_231 (Dense)           (None, 500)               4400000   \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 1500)              751500    \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 1200)              1801200   \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 1200)              1441200   \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 600)               720600    \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 600)               360600    \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 1)                 601       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,475,701\n",
      "Trainable params: 9,475,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Attempt 3, using constant amount of nodes with more layers and declining nodes\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer = 1500\n",
    "hidden_nodes_layer2 = 1500\n",
    "hidden_nodes_layer3 = 1200\n",
    "hidden_nodes_layer4 = 1200\n",
    "hidden_nodes_layer5 = 600\n",
    "hidden_nodes_layer6 = 600\n",
    "\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(input_dim = number_input_features, units=hidden_nodes_layer1, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"elu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"elu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"elu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"relu\"))\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer6, activation=\"relu\"))\n",
    "\n",
    "\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "804/804 [==============================] - 89s 105ms/step - loss: 0.6103 - accuracy: 0.6813\n",
      "Epoch 2/5\n",
      "804/804 [==============================] - 84s 105ms/step - loss: 0.5352 - accuracy: 0.7510\n",
      "Epoch 3/5\n",
      "804/804 [==============================] - 80s 100ms/step - loss: 0.4130 - accuracy: 0.8090\n",
      "Epoch 4/5\n",
      "804/804 [==============================] - 80s 100ms/step - loss: 0.4022 - accuracy: 0.8106\n",
      "Epoch 5/5\n",
      "804/804 [==============================] - 85s 106ms/step - loss: 0.3998 - accuracy: 0.8123\n"
     ]
    }
   ],
   "source": [
    "# Attempt 3 Model Test\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 3s - loss: 0.6353 - accuracy: 0.7062 - 3s/epoch - 11ms/step\n",
      "Loss: 0.6353119015693665, Accuracy: 0.7062390446662903\n"
     ]
    }
   ],
   "source": [
    "# Attempt 3 Evaluation\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save_weights(\"AlphabetSoupCharity_Optimization.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
